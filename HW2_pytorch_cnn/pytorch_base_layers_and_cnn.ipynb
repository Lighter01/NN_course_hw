{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2. Свертки и базовые слои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "import tqdm.notebook as tq\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-9\n",
    "\n",
    "SEED = 161020204\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "numpy_rng = np.random.default_rng(SEED)\n",
    "torch_rng = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABlCAYAAADK3JXbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEPUlEQVR4nO3cMWtrdRzG8X/DvQm9NCfQMSQ6FFzF2dlJByddBHF0cxWHLr4AVwcHwXfgIvhOHCo0EHASkt5baaXH4XIdhHjPOT7l+G8/n7UZfjxtUr6k6VHbtm0BAAAImox9AAAA8PAIDQAAIE5oAAAAcUIDAACIExoAAECc0AAAAOKEBgAAEPeky4Pu7u7Kdrst8/m8HB0d3fdNAADA/1TbtmW/35flclkmk8PvW3QKje12W9brdew4AACgbpvNpqxWq4Nf7xQa8/m8lFLKx5/9WqbTeeayR+Dr394f+4QqvfnFR2OfUJ3vv/t07BOq9OG7n499QnXeevubsU+o0i/f/jD2CdX5+avfxz6hSu/9+OXYJ1SnfeeTsU+ozu75bXnjg5/+boRDOoXGqz+Xmk7nZTpr/vt1j0TztNO8/NPJ8dgXVOfZ1PNyiOb46dgnVGdy4mdtiGbqda2vZ/PrsU+oUnPsOdpXe+J3wVCv+0iFD4MDAABxQgMAAIgTGgAAQJzQAAAA4oQGAAAQJzQAAIA4oQEAAMQJDQAAIE5oAAAAcUIDAACIExoAAECc0AAAAOKEBgAAECc0AACAOKEBAADECQ0AACBOaAAAAHFCAwAAiBMaAABAnNAAAADihAYAABAnNAAAgDihAQAAxAkNAAAgTmgAAABxQgMAAIgTGgAAQJzQAAAA4oQGAAAQJzQAAIA4oQEAAMQJDQAAIE5oAAAAcUIDAACIExoAAECc0AAAAOKEBgAAECc0AACAOKEBAADECQ0AACBOaAAAAHFCAwAAiBMaAABAnNAAAADihAYAABAnNAAAgDihAQAAxAkNAAAgTmgAAABxQgMAAIgTGgAAQJzQAAAA4oQGAAAQJzQAAIA4oQEAAMQJDQAAIE5oAAAAcUIDAACIExoAAECc0AAAAOKEBgAAECc0AACAOKEBAADECQ0AACBOaAAAAHFCAwAAiBMaAABAnNAAAADihAYAABAnNAAAgDihAQAAxAkNAAAgTmgAAABxT7o8qG3bUkopNzf7ez3modnd/jn2CXW6uh77guq8uNmNfUKVdte3Y59QnbsrP2tD7G68rvX1Yv/H2CdUaXftOdpXe+V3QV+75y83e9UIhxy1r3tEKeXi4qKcnZ1lLgMAAKq32WzKarU6+PVO72icnp6WUkq5vLwsi8Uic9kjsNvtynq9LpvNpjRNM/Y5VbDZMHbrz2bD2K0/mw1jt/5sNozd+mvbtuz3+7JcLv/1cZ1CYzJ5+VGOxWLhGzBA0zR268lmw9itP5sNY7f+bDaM3fqz2TB266fLmw8+DA4AAMQJDQAAIK5TaMxms3J+fl5ms9l93/Og2K0/mw1jt/5sNozd+rPZMHbrz2bD2O3+dPqvUwAAAH340ykAACBOaAAAAHFCAwAAiBMaAABAnNAAAADihAYAABAnNAAAgDihAQAAxP0FILCzOVq7DVAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример сетки, на которой будут проверяться новые слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([60000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./datasets', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./datasets', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_dataset.data.size(), train_dataset.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenedDataset(Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.original_dataset[index]\n",
    "        image = image.view(-1)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FlattenedDataset(train_dataset)\n",
    "test_dataset = FlattenedDataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Это задание будет являться духовным наследником первого. Вы уже научились делать шаги градиентного спуска и вспомнили, как устроен базовый линейный слой. На этой неделе мы построим прототип базового фреймворка до конца (собственно, многое вы сможете скопировать, если захотите). Хоть вы уже и знаете о torch.nn, для выполнения задания его использовать нельзя. Однако все элементы, которые вы будете реализовывать, достаточно просты.\n",
    "\n",
    "**Задача 1. (2 балла):** реализуйте слой BatchNorm (nn.BatchNorm).\n",
    "\n",
    "**Задача 2. (2 балла):** реализуйте слой Linear (nn.Linear).\n",
    "\n",
    "**Задача 3. (2 балла):** реализуйте слой Dropout(nn.Dropout)\n",
    "\n",
    "**Задача 4. (2 балла):** реализуйте одно или более из:\n",
    "\n",
    "- слой ReLU(nn.ReLU)\n",
    "- слой Sigmoid(nn.Sigmoid)\n",
    "- слой Softmax(nn.Softmax)\n",
    "\n",
    "**Задача 5. (2 балла):** Вы получите по 1 дополнительному баллу за слой, если реализуете в рамках фреймворка из задания 3 прошлой работы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchNorm1d(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_features: int, \n",
    "                 eps: float = 1e-8, \n",
    "                 momentum: float = 0.1\n",
    "    ) -> None:\n",
    "        super(MyBatchNorm1d, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "        self.register_buffer('exp_avg_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('exp_avg_var', torch.ones(num_features))\n",
    "\n",
    "    def __call__(self, input: torch.Tensor):\n",
    "        # forward pass\n",
    "        if self.training:\n",
    "            if input.ndim == 2:\n",
    "                dim = 0\n",
    "            elif input.ndim == 3:\n",
    "                dim = (0,1)\n",
    "            input_mean = input.mean(dim, keepdim=True)\n",
    "            input_var = input.var(dim, keepdim=True)\n",
    "        else:\n",
    "            input_mean = self.exp_avg_mean\n",
    "            input_var = self.exp_avg_var\n",
    "        x_hat = (input - input_mean) / torch.sqrt(input_var + self.eps)\n",
    "        self.out = self.gamma * x_hat + self.beta\n",
    "        # update the buffers (running mean and variance)\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.exp_avg_mean = (1 - self.momentum) * self.exp_avg_mean + self.momentum * input_mean\n",
    "                self.exp_avg_var = (1 - self.momentum) * self.exp_avg_var + self.momentum * input_var\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация nn.Linear в [pytorch](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)\n",
    "\n",
    "Как работает [_calculate_fan_in_and_fan_out](https://github.com/pytorch/pytorch/blob/4557f6e339e7550b735067296ed479acc02e0487/torch/nn/init.py#L345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 bias: bool = True\n",
    "    ) -> None:\n",
    "        super(MyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # kaiming normal init for ReLU\n",
    "        self.weight = nn.Parameter(torch.empty((in_features, out_features)))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        gain = 2 ** 0.5\n",
    "        torch.nn.init.normal_(self.weight, mean = 0, std = gain / (self.in_features ** 0.5))\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.normal_(self.bias, mean = 0, std = gain / (self.in_features ** 0.5))\n",
    "\n",
    "    def __call__(self, input: torch.Tensor):\n",
    "        self.out = input.matmul(self.weight)\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация в [Pytorch](https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#dropout1d)\n",
    "\n",
    "Реализация в [Pytorch (cpp)](https://github.com/pytorch/pytorch/blob/a1b22e369bed57990a57f9efbae201570ad6b824/aten/src/ATen/native/Dropout.cpp#L62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDropout1d(nn.Module):\n",
    "\n",
    "    def __init__(self, p: float = 0.5, inplace: bool = False) -> None:\n",
    "        super(MyDropout1d, self).__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(f\"dropout probability has to be between 0 and 1, but got {p}\")\n",
    "        self.p = p\n",
    "        self.inplace = inplace\n",
    "        self.training = True # БУДЕТ ЛИ ИЗМЕНЯТЬСЯ В РЕЖИМЕ model.eval()?\n",
    "\n",
    "    def __call__(self, input: torch.Tensor):\n",
    "        if self.training:\n",
    "            inp_dim = input.dim()\n",
    "            if inp_dim not in (2, 3):\n",
    "                raise RuntimeError(f\"dropout1d: Expected 2D or 3D input, but received a {inp_dim}D input. \")\n",
    "            # is_batched = inp_dim == 3\n",
    "            # if not is_batched:\n",
    "            #     input = input.unsqueeze_(0) if self.inplace else input.unsqueeze(0)\n",
    "            if self.p == 1:\n",
    "                return torch.zeros_like(input)\n",
    "            probs = torch.full_like(input, self.p)\n",
    "            mask = torch.bernoulli(probs, generator=torch_rng)\n",
    "            self.out = input.mul(mask)\n",
    "            return self.out\n",
    "        else:\n",
    "            return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyReLU(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyReLU, self).__init__()\n",
    "\n",
    "    def __call__(self, input):\n",
    "        self.out = torch.where(input > 0, input, 0)\n",
    "        # self.out = torch.relu(input)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySoftmax(nn.Module):\n",
    "\n",
    "    def __init__(self, dim: Optional[int] = None):\n",
    "        super(MySoftmax, self).__init__()\n",
    "        self.dim = dim if dim is not None else 1 # нужна логика получше\n",
    "\n",
    "    def __call__(self, input):\n",
    "        maxes = torch.max(input, dim=1, keepdim=True)[0]\n",
    "        x_exp = torch.exp(input - maxes)\n",
    "        x_exp_sum = torch.sum(x_exp, dim=self.dim, keepdim=True)\n",
    "        self.out = x_exp / x_exp_sum\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспериментальная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = nn.Sequential(\n",
    "    MyLinear(784, 256),   # Flattened MNIST images (28x28) -> hidden layer\n",
    "    MyBatchNorm1d(256),   # BatchNorm\n",
    "    MyReLU(),             # ReLU activation\n",
    "    MyDropout1d(p=0.5),    # Dropout layer\n",
    "    MyLinear(256, 10),    # Hidden -> output layer (10 classes for MNIST)\n",
    "    MySoftmax(dim=1)      # Softmax for classification\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model_seq.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204042"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (784 * 256 + 256) + 256 * 2 + (256 * 10 + 10)\n",
    "sum(p.numel() for p in model_seq.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_sequential(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.5998559447606404\n",
      "Epoch 2/5, Loss: 1.5424904745101928\n",
      "Epoch 3/5, Loss: 1.5301774183909098\n",
      "Epoch 4/5, Loss: 1.5216965227127075\n",
      "Epoch 5/5, Loss: 1.516130871073405\n"
     ]
    }
   ],
   "source": [
    "train_model_sequential(model_seq, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.34%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_seq, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Торчевская аналогичная сеть для сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(784, 256),   # Flattened MNIST images (28x28) -> hidden layer\n",
    "    nn.BatchNorm1d(256),   # BatchNorm\n",
    "    nn.ReLU(),             # ReLU activation\n",
    "    nn.Dropout1d(p=0.5),    # Dropout layer\n",
    "    nn.Linear(256, 10),    # Hidden -> output layer (10 classes for MNIST)\n",
    "    nn.Softmax(dim=1)      # Softmax for classification\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model_seq.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.9341435103098552\n",
      "Epoch 2/5, Loss: 1.9134720966974894\n",
      "Epoch 3/5, Loss: 1.900992161432902\n",
      "Epoch 4/5, Loss: 1.9015678155899047\n",
      "Epoch 5/5, Loss: 1.8977774666468303\n"
     ]
    }
   ],
   "source": [
    "train_model_sequential(model_seq, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.32%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_seq, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expenv python 3.11.5",
   "language": "python",
   "name": "expenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
